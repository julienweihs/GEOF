{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperature and CO2 locally and Globally\n",
    "\n",
    "#### This script is made for the learningday for technical staff at UiB the 22 of February 2024. \n",
    "*I've made this type of exercises as part of the project \"Ekte Data\" in collaboration with \"Skolelaboratoriet\" for natural sciences at UiB. The past two years we have focused on developing an intro course to programming in Python. All the exercises are based on real data sets and scientific questions. Our goal is to make the connection between natural sciences, mathematics, and programming clear. You can find more programming exercises and tools to get started [here](https://github.com/irendundas/EkteData).*\n",
    " \n",
    "V√•r Dundas, PhD candidate in physical oceanography at the Geophysical Institute, UiB\n",
    "\n",
    "------------------\n",
    "The goal of this exercise is to give an intro to how you can work with data in Python. We use data of temperature and CO2 to go though: \n",
    "- **Loading data into your script** üíæ\n",
    "- **Use of libraries** üìñ\n",
    "- **Use of functions** üéØ\n",
    "- **How to structure your variables** üóÉÔ∏è\n",
    "- **Visualization** üé®\n",
    "\n",
    "The cases we look at are\n",
    "- Temperatureanomlies from Bergen and globally\n",
    "- Linear trends for different time periods\n",
    "- Anomalies in global CO2 in the atmosphere\n",
    "- Different ways to present and compare data \n",
    "\n",
    "Vi use four data sets:\n",
    "- Temperature data for Bergen: [download here](https://github.com/irendundas/EkteData/blob/main/data/Bergen_temp1862_2022.txt). This data set is compiled by Hele Drange, and is based on data from the Norwegian Meteorological Institute. \n",
    "- Temperature data globally: [download here](https://climate.metoffice.cloud/temperature.html#datasets) (scroll down to \"Get the data\" and download HadCRUT5, NOAAGlobalTemp, or GISTEMP as csv-file. In this example I use HadCRUT5). \n",
    "- CO2 data until 2004 (NOAA): [download here](https://www1.ncdc.noaa.gov/pub/data/paleo/icecore/antarctica/law/law2006.txt). These data are based on ice cores. The dataset has a lot of information we do not need, and we load it into this script in a tidy way roughly halfway into the exercise.  \n",
    "- CO2 data from 1959 until today (NOAA): [download here](https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_annmean_mlo.txt) \n",
    "\n",
    "The temperature stripe figures in this exercise are inspired by [Ed Hawkins' original figure ](https://www.wfla.com/wp-content/uploads/sites/71/2022/06/PAGES2K-ED-HAWKINS-CLIMATE-STRIPES.jpg?w=900).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the libraries you need üìñ\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL_SIZE = 13\n",
    "MEDIUM_SIZE = 17\n",
    "BIGGER_SIZE = 14\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=MEDIUM_SIZE)    # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Temperature\n",
    "In this part we look at temperature anomalies. This means that we look at temperature deviations relative to a defines reference period. For HadCRUT5 the reference period is 1961‚Äì1990 ([Morice et al., 2020](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2019JD032361)).\n",
    "\n",
    "### Import the data set of global temperature\n",
    "Follow this [link](https://climate.metoffice.cloud/temperature.html#datasets) and download one of the data sets under **Global mean temperature**. Make sure that you save the file somewhere logical. \n",
    "Below I use the data from HadCRUT5.\n",
    "Import the data of global temperature into Python. We use the library \"Pandas\". This library is perfect for working with data in 2D. If you need to import data with more than two dimensions I would recommend the library \"xarray\". A lot of the functionality is the same, but it's specifically tailored for multiple dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify which file you want to import and where on your computer it's located\n",
    "\n",
    "# !!! Change the path below to the path where you have the file on your computer!!!\n",
    "# !!! If you have the data in the same folder as this script, you don't need to specify the path. \n",
    "path='W:/Work/Documents/EkteData/ikkeGit/temperaturstriper'\n",
    "file='/gmt_HadCRUT5.csv'\n",
    "\n",
    "# Make sure that the result of path+file is exactly where you have the file on your computer\n",
    "path+file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Pandas to import the data. \n",
    "Look [here](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html) for an explanation of the keywords (sep, index_col etc).\n",
    "\n",
    "To know which keyword arguments (**kwargs in the documentation) you need to use, you have to knwo what your file looks like. I always open my file in a text editor (e.g., notepad) to inspect how columns are separated, what's used as the decimal sign, if there's a header or footer etc. For this purpose you cannot open the file in e.g., excel because this information is not visible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data set üíæ\n",
    "df = pd.read_csv(\n",
    "    path+file, \n",
    "    sep=',', \n",
    "    decimal='.', \n",
    "    index_col=False, \n",
    "    header=4,\n",
    "    skipinitialspace=True # Skip spaces after delimiter.\n",
    ")\n",
    "\n",
    "# From the doc: index_col=False can be used to force pandas to not use the \n",
    "# first column as the index, e.g. when you have a malformed file with \n",
    "# delimiters at the end of each line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the data set to see what it looks like.Did it import properly? \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üóÉÔ∏è\n",
    "# Make two empty \"dictionaries\". One for time and one for temperature so that you don't have to keep control of so many \n",
    "# variables when we also import time and temp from Bergen below\n",
    "time, temp={},{}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the first column (iloc[:,0]) to \"time\" oand the second column (iloc[:,1]) to \"temp\" üóÉÔ∏è\n",
    "time['Global']=np.copy(df.iloc[:,0])\n",
    "temp['Global']=np.copy(df.iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make a figure to get a sense of the data üé®\n",
    "plt.plot(time['Global'], temp['Global'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the data set over temperature in Bergen\n",
    "The data set is available [here](github.com/irendundas/EkteData/blob/main/data/Bergen_temp1862_2022.txt).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üíæ\n",
    "path='W:/Work/Documents/EkteData/EkteData/data'\n",
    "file='/Bergen_temp1862_2022.txt'\n",
    "\n",
    "# \"Keyword arguments\" here are a bit different from da data import above because the dataset from Bergen is a bit\n",
    "# differently organized than the global data set.\n",
    "df = pd.read_csv(\n",
    "    path+file, \n",
    "    sep=' ', \n",
    "    decimal='.', \n",
    "    index_col=False, \n",
    "    header=5,\n",
    "    skipinitialspace=True \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save time and temperature as their own variables in the dictionaries time and temp: üóÉÔ∏è\n",
    "\n",
    "time['Bergen']=np.copy(df.iloc[:,0])\n",
    "# We want to look at anomalies, so we set the third column to temp['Bergen']\n",
    "temp['Bergen']=np.copy(df.iloc[:,3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot temperature from both global and Bergen in the same figure üé®\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.plot(time['Global'], temp['Global'], label='Global')\n",
    "plt.plot(time['Bergen'], temp['Bergen'], label='Bergen')\n",
    "plt.legend()\n",
    "plt.ylabel('Temperature anomalies')\n",
    "plt.xlim([1850,2023])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions**\n",
    "\n",
    "- Why do the temperature anomalies vary so much more from year to year in Bergen than globally?\n",
    "- Why is the variability still so similar on longer time scales?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________\n",
    "## Part 2: Trends - long term changes in Bergen: \n",
    "\n",
    "**NB! For the \"Learning day for technical employees at UiB\": run quickly through the following cells until the cell that reads \"Does a second order polynomial describe the change in temperature better than the linear trend?\".**\n",
    "\n",
    "Estimate three trend lines, e.g.:\n",
    "- One for the whole data set, \n",
    "- one for the period from when I'm born until today, and\n",
    "- one for the period from when you're born (ca 1970?) until today. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the index of year 1994 and 1970. üéØ\n",
    "id94=np.where(time['Bergen']==1994)[0][0]\n",
    "id70=np.where(time['Bergen']==1970)[0][0]\n",
    "\n",
    "# Check that the indices we found are correct. \n",
    "time['Bergen'][id94], time['Bergen'][id70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üé®\n",
    "plt.figure(figsize=(10,5))\n",
    "# The whole time series\n",
    "plt.plot(time['Bergen'], temp['Bergen'], 'C1', label='Bergen') \n",
    "# The trend of the whole time seriesüéØ\n",
    "a, b = np.polyfit(time['Bergen'], temp['Bergen'], 1) \n",
    "plt.plot(time['Bergen'], a*time['Bergen'] + b, 'k', label='trend: 1860-2023')\n",
    " # The trend since 1970\n",
    "a, b = np.polyfit(time['Bergen'][id70:], temp['Bergen'][id70:], 1)\n",
    "plt.plot(\n",
    "    time['Bergen'][id70:], a*time['Bergen'][id70:] + b, \n",
    "    'k', label='trend: 1970-2023', ls=':'\n",
    ")\n",
    "# The trend since 1994\n",
    "a, b = np.polyfit(time['Bergen'][id94:], temp['Bergen'][id94:], 1) \n",
    "plt.plot(\n",
    "    time['Bergen'][id94:], a*time['Bergen'][id94:] + b, \n",
    "    'k', label='trend: 1994-2023', ls='--'\n",
    ")\n",
    "\n",
    "plt.legend()\n",
    "plt.ylabel('Temperature anomaly')\n",
    "\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = np.polyfit(time['Bergen'], temp['Bergen'], 1) # The trend of the full time series\n",
    "x=(a*time['Bergen'][-1] + b)-(a*time['Bergen'][0] + b)\n",
    "x=\"{:.1f}\".format(x) # Only print out one decimal. üéØ\n",
    "\n",
    "print(\n",
    "    'The trend indicates that for the full period, the temperature in Bergen has increased by ', \n",
    "    x, 'grader'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the figure is more tidy with a for-loop üéØüé®\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.plot(time['Bergen'], temp['Bergen'], 'C1', label='Bergen')\n",
    "\n",
    "idt=[0, id70, id94]\n",
    "labels=['trend: 1860-2023', 'trend: 1970-2023', 'trend: 1994-2023']\n",
    "ls=['-', ':', '--'] # Linestyle\n",
    "for count,start in enumerate(idt):\n",
    "    a, b = np.polyfit(time['Bergen'][start:], temp['Bergen'][start:], 1)   \n",
    "    plt.plot(\n",
    "        time['Bergen'][start:], a*time['Bergen'][start:] + b, \n",
    "        'k', label=labels[count], lw=2, ls=ls[count]\n",
    "    )\n",
    "plt.ylabel('Temperature anomaly')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions**\n",
    "- What is the difference between the trend lines?\n",
    "- What happens to the trend lines when the start date for the estimation period increases?\n",
    "- What does this mean physically?\n",
    "\n",
    "**Can you trust the trend lines?**\n",
    "- Estimate the trend for the two periods 1977-2000 and 1990-2013.\n",
    "- Assume that both the trends represent the change in temperature for Bergen for the past 160 years. \n",
    "    - According to trend nr 1, how much has the trend increased since the beginning of the time series?\n",
    "    - And avvording to trend nr 2?\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üé®\n",
    "plt.figure(figsize=(10,5))\n",
    "# The whole time series \n",
    "plt.plot(time['Bergen'], temp['Bergen'], 'C1', label='Bergen') \n",
    "id1=np.where(time['Bergen']==1990)[0][0]\n",
    "id2=np.where(time['Bergen']==2013)[0][0]+1\n",
    "# The trend between 1990 and 2013\n",
    "a, b = np.polyfit(time['Bergen'][id1:id2], temp['Bergen'][id1:id2], 1)\n",
    "print('change the past 160 years: ', a*160, 'degrees')\n",
    "plt.plot(\n",
    "    time['Bergen'][id1:id2], a*time['Bergen'][id1:id2] + b, \n",
    "    'k', label='trend: 1990-2013', ls='--'\n",
    ")\n",
    "id1=np.where(time['Bergen']==1977)[0][0]\n",
    "id2=np.where(time['Bergen']==2000)[0][0]+1\n",
    "# The trend between 1977 and 2000\n",
    "a, b = np.polyfit(time['Bergen'][id1:id2], temp['Bergen'][id1:id2], 1)\n",
    "print('change the past 160 years: ', a*160, 'degrees')\n",
    "plt.plot(\n",
    "    time['Bergen'][id1:id2], a*time['Bergen'][id1:id2] + b, \n",
    "    'k', label='trend: 1977-2000', ls='-'\n",
    ")\n",
    "\n",
    "plt.legend()\n",
    "plt.ylabel('Temperature anomaly')\n",
    "plt.xlim(1960, 2023)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The difference is large! Always make sure that trends you present (or someone presents to you) are robust. Trends should not be strongly influenced by the choice of start and end. \n",
    "\n",
    "\n",
    "_____________\n",
    "### Does a second order polynomial describe the change in temperature better than the linear trend?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üé®\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(time['Bergen'], temp['Bergen'], 'C1', label='Bergen')\n",
    "# The trend of the full time series\n",
    "a, b = np.polyfit(time['Bergen'], temp['Bergen'], 1) # üéØ\n",
    "plt.plot(time['Bergen'], a*time['Bergen'] + b, 'k', label='line√¶r tilpasning', ls='-')\n",
    "\n",
    "# Second order polynomial fitted to the data\n",
    "a = np.polyfit(time['Bergen'], temp['Bergen'], 2) \n",
    "plt.plot(\n",
    "    time['Bergen'], \n",
    "    a[0]*time['Bergen']**2 + a[1]*time['Bergen'] + a[2], \n",
    "    'k', label='second order polynomial', ls='--'\n",
    ")\n",
    "plt.ylabel('Temperature anomaly')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**\n",
    "- What kind of information do we get from the second order polynomial that we did not get from the linear trend line?\n",
    "\n",
    "**Exercise: What about the trend of the Global temperature?**\n",
    "- Estimate the trendline for the global time series. \n",
    "- Plot the global trend line and the trend line for Bergen in the same figure to compare them.\n",
    "- Tip: Start the time series in 1862 to that the two time series cover the same period. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time['Bergen'][0], time['Global'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id62=np.where(time['Global']==1862)[0][0] # üéØ\n",
    "\n",
    "a, b = np.polyfit(time['Global'][id62:], temp['Global'][id62:], 1)   \n",
    "plt.plot(time['Global'][id62:], a*time['Global'][id62:] + b, label='Global')\n",
    "\n",
    "a, b = np.polyfit(time['Bergen'], temp['Bergen'], 1)   \n",
    "plt.plot(time['Bergen'], a*time['Bergen'] + b, label='Bergen')\n",
    "# If you prefer, ou can use the \"np.polyval\" function when plotting the trend. \n",
    "# This is reduces the potential for error if you are plotting a polynomial of higher order. \n",
    "plt.plot(time['Bergen'], np.polyval([a,b], time['Bergen']), label='Bergen', ls=':')\n",
    "plt.legend()\n",
    "plt.ylabel('Temperature trend')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**\n",
    "- What does the two linear trends tell us about the global temperature change vs the temperature change in Bergen?\n",
    "\n",
    "______________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature stripes üé®\n",
    "**Plot the time series as a histogram with the colors used in the original \"temperature stripe\"-figure made by [Ed Hawkins](https://www.wfla.com/wp-content/uploads/sites/71/2022/06/PAGES2K-ED-HAWKINS-CLIMATE-STRIPES.jpg?w=900).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates a color map that uses the colors from the original temperature stripe figure\n",
    "# There are 8 blue and 8 red colors. üéØ\n",
    "cmap = ListedColormap([\n",
    "    '#08306b', '#08519c', '#2171b5', '#4292c6',\n",
    "    '#6baed6', '#9ecae1', '#c6dbef', '#deebf7',\n",
    "    '#fee0d2', '#fcbba1', '#fc9272', '#fb6a4a',\n",
    "    '#ef3b2c', '#cb181d', '#a50f15', '#67000d',\n",
    "])\n",
    "\n",
    "# Note that this is not how I would usually specify a color - RGB is more intuitive. But since we want the \n",
    "# exact colors we use hex codes as here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: In the code three cells below you'll see this line: `color=cmap((temp['Global']+max_anomaly)/(2*max_anomaly))`, where `max_anomaly=max(temp['Global'])` is specified just below. This makes the barplot take the normalized temperature time series as its colors. It's a bit complicated to explain how this works, and it's not the main point of this exercise, so feel free to skip the explanation of this below. \n",
    "\n",
    "We want all the temperature anomalies that are below 0 to be blue, and all the anomalies that are over 0 to be red. Further, we want the maximum positive anomalies to be the darkest red color. To achieve this we normalize the temperature values to be between 0 and 1. This happens here: `(temp['Global']+max_anomaly)/(2*max_anomaly)`. See the figure below. \n",
    "\n",
    "The non-normalized anomalies in the beginning of the time series are close to 0. After the normalizing these values are close to 0.5, i.e., just between 0 and 1. When plotting the temperature stripes the bars in the start are therefore very pale because the colors at the middle of the colormap we made are close to white. Towards the end of the time series, the termperature anomalies reaches its maximum, and the colors are therefore the darkest red of our colormap. The variable `max_anomaly` is the largest temperature anomaly. By using this value in the nomalizing the largest anomaly gets the darkest red color. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_anomaly=max(temp['Global']) # üéØ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This figure shows that anomalies near 0 becomes 0.5, while the maximum anomaly becomes 1 after the nomalizing.\n",
    "# If there were negative anomalies that were as strong as the positive anomalies, these would have been zero, \n",
    "# and they would be dark blue in the bar plot.\n",
    "fig, ax=plt.subplots(1, 1, figsize=(10, 4))\n",
    "plt.plot((temp['Global']+max_anomaly)/(2*max_anomaly), label='normalized')\n",
    "plt.plot(temp['Global'], label='not normalized')\n",
    "plt.legend(ncol=2)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéØüé®\n",
    "fig, ax=plt.subplots(1, 1, figsize=(10, 4))\n",
    "plt.bar(\n",
    "    time['Global'], temp['Global'], \n",
    "    color=cmap((temp['Global']+max_anomaly)/(2*max_anomaly)) # normalize data values to the range [0, 1]\n",
    ") \n",
    "    \n",
    "plt.plot(time['Global'], temp['Global'], 'k', linewidth=0.5)\n",
    "plt.ylabel('Temperature anomaly [¬∞C]')\n",
    "plt.title('Global')\n",
    "plt.ylim(-2, 2.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the plot of Bergen data with the global temperature maxima so that the two plaots can be compared. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéØüé®\n",
    "fig, ax=plt.subplots(1, 1, figsize=(10, 4))\n",
    "plt.bar(time['Bergen'], temp['Bergen'], color=cmap((temp['Bergen']+max_anomaly)/(2*max_anomaly)))\n",
    "plt.ylim(-2, 2.4)\n",
    "\n",
    "# Add the trends from earlier\n",
    "idt=[0, id70]\n",
    "for count,start in enumerate(idt):\n",
    "    a, b = np.polyfit(time['Bergen'][start:], temp['Bergen'][start:], 1)   \n",
    "    plt.plot(\n",
    "        time['Bergen'][start:], a*time['Bergen'][start:] + b, \n",
    "        'k', linewidth=1\n",
    "    )\n",
    "plt.ylabel('Temperature anomaly [¬∞C]')\n",
    "plt.title('Bergen')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the barplot of Bergen there are som dark blue colors as well. This is because there were both strong negative and positive anomalies during this period in Bergen. \n",
    "\n",
    "________________________\n",
    "### Part 3: CO2 in the atmosphere üíæ\n",
    "\n",
    "The relationship between temperature and the CO2 in the atmosphere becomes clear if we plot CO2 in the same figure as temperature. \n",
    "\n",
    "We have to use two data sets over CO2 and combine them since one of them ends in 2004 and the other starts in 1959.The former is based on ice cores from Law station in Antarctica, while the latter is from Mauna Loa in Hawaii. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data set ove CO2 from ice cores collected in Antarctica (1832-2004) üíæ\n",
    "sti=r'W:\\\\Work\\\\Documents\\\\EkteData\\\\ikkeGit\\\\temperaturstriper'\n",
    "fil=r'\\\\Law_co2_complete.txt'\n",
    "\n",
    "df = pd.read_csv(\n",
    "    sti+fil, \n",
    "    delim_whitespace=True,\n",
    "    decimal='.', \n",
    "    index_col=False, \n",
    "    # there are 2013 lines with information at the start of the data set that we don't need\n",
    "    skiprows=2013, \n",
    "    # there are 3676-2187 lines with information at the end of the data set that we don't need,\n",
    "    # i.e., the file has 3676 lines, and the info we need ends on line 2187\n",
    "    skipfooter=3676-2187,\n",
    "    engine='python'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üóÉÔ∏è\n",
    "timeco2_law=np.copy(df.iloc[:,0])\n",
    "co2_law=np.copy(df.iloc[:,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üé®\n",
    "plt.plot(timeco2_law, co2_law)\n",
    "plt.ylabel('CO2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data set of CO2 from direct observations (1959-) üíæ\n",
    "fil='/NOAA_CO2.txt'\n",
    "\n",
    "df = pd.read_csv(\n",
    "    sti+fil, \n",
    "    sep=' ', \n",
    "    decimal='.', \n",
    "    skipinitialspace=True,\n",
    "    skiprows=55\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üóÉÔ∏è\n",
    "timeco2_noaa=np.copy(df.iloc[:,0])\n",
    "co2_noaa=np.copy(df.iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üé®\n",
    "plt.plot(timeco2_law, co2_law)\n",
    "plt.plot(timeco2_noaa, co2_noaa)\n",
    "plt.ylabel('CO2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    'The data sets overlap. The data set from Law ends in',\n",
    "    timeco2_law[-1], \n",
    "    'while the data set from Mauna Loa starts in',\n",
    "    timeco2_noaa[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üóÉÔ∏è üéØ\n",
    "# To combine the two data sets we use the mean of the two sources in the period that overlaps. \n",
    "# The figure above gives us confidence that this is reasonable. \n",
    "# We make two new variables: timeco2 and co2\n",
    "\n",
    "# First, make the new time vector with np.arange(). \n",
    "# np.arange() takes three inputs: start, stop, and step.\n",
    "timeco2=np.arange(timeco2_law[0], timeco2_noaa[-1]+1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an empty array that we can fill with the CO2 data üóÉÔ∏è üéØ\n",
    "# Give this one two columns so that we can fill data from Law into one column and data from Muana Loa in the other.\n",
    "# But: Let them have the same time vector and fill the columns with NaN where the two respective time series do not have data. \n",
    "co2=np.nan*np.zeros((len(timeco2),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üóÉÔ∏è\n",
    "# Fill data from Law into column 0\n",
    "# This spans years 1832 through 2004\n",
    "id2004=np.where(timeco2_law==timeco2_law[-1])[0][0]+1 # +1 because of \"through 2004\"\n",
    "co2[:id2004, 0]=co2_law\n",
    "\n",
    "# Fill data from Muana Loa into column 1\n",
    "# This spans years 1959 through 2022 (or later depending on when you downloaded the data)\n",
    "id1959=np.where(timeco2==timeco2_noaa[0])[0][0]\n",
    "co2[id1959:, 1]=co2_noaa\n",
    "\n",
    "# Redefine the variable \"co2\" to be the average of the variable \"co2\" üéØ\n",
    "co2=np.nanmean(co2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üé®\n",
    "# Plot CO2 from Law and Muana Loa as thin black lines in the background\n",
    "plt.plot(timeco2_law, co2_law, 'k', lw=.5, label='Law')\n",
    "plt.plot(timeco2_noaa, co2_noaa, 'k', lw=.5, label='Muana Loa')\n",
    "# Plot CO2 as the average from Law and Muana Loa above in blue \n",
    "# to check that the estimate is sensible. \n",
    "plt.plot(timeco2, co2, label='Average')\n",
    "plt.ylabel('CO2')\n",
    "plt.legend()\n",
    "\n",
    "# This is a reasonable solution since the overlapping measurements have very similar values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________\n",
    "### Everything wrapped up:\n",
    "#### Make a figure with temperature stripes, a second order fitted polynomial, and global CO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üé®\n",
    "fig, ax=plt.subplots(1, 1, figsize=(10, 4))\n",
    "ax.bar(\n",
    "    time['Global'], temp['Global'], \n",
    "    color=cmap((temp['Global']+max_anomaly)/(2*max_anomaly)) # normalize data values to the range [0, 1]\n",
    ") \n",
    "plt.title('Global')\n",
    "ax.set_ylim(-0.5, 1.4)\n",
    "\n",
    "# Add the polynomial\n",
    "a,b,c = np.polyfit(time['Global'], temp['Global'], 2)   \n",
    "ax.plot(\n",
    "    time['Global'], a*time['Global']**2 \n",
    "    + b*time['Global'] + c, \n",
    "    'k'\n",
    ")\n",
    "plt.ylabel('Temperature anomaly [¬∞C]')\n",
    "    \n",
    "# Add global CO2\n",
    "ax2=ax.twinx()\n",
    "ax2.plot(timeco2, co2, 'C2', linewidth=3)\n",
    "# Adjust the y-axis of the figure to show the information more clearly. \n",
    "ax2.set_ylim(250, 430)\n",
    "\n",
    "ax2.spines['right'].set_color('C2')\n",
    "ax2.tick_params(axis='y', colors='C2')\n",
    "ax2.yaxis.label.set_color('C2')\n",
    "ax2.set_ylabel('Global CO2')\n",
    "plt.xlim(time['Global'][0], time['Global'][-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Honest data visualization\n",
    "In the figure above, we've adjusted the left and right y-axis so that the figure clearly shows what we want to communicate, i.e., that temperature and CO2 is related. \n",
    "\n",
    "But how do you feel about this? Is it ok to adjust the axis as we want?\n",
    "\n",
    "It's important to conciously visualizing data and results in an honest way. Double y-axis can be a good way to indicate a relationship between two variables, but it can also be a pit fall as illustrated below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üé®\n",
    "# Make a subplot with three panels\n",
    "fig, axs = plt.subplots(1, 3, figsize=(10, 4))\n",
    "\n",
    "# Make one set of left hand y-limits for each panel\n",
    "ylim=[(-0.5, 1.4), (-0.5, 1.4), (-5, 20)] # ylim for temperature\n",
    "# Make one set of right hand y-limits for each panel\n",
    "ylim2=[(-500, 1000), (250, 430), (250, 430)] # ylim for CO2\n",
    "\n",
    "for count, ax in enumerate(axs): # Loop through the three panels of the subplot\n",
    "    # Adjust the left axis in the figure\n",
    "    ax.set_ylim(ylim[count])\n",
    "\n",
    "    # Polynomial from earlier\n",
    "    a,b,c = np.polyfit(time['Global'], temp['Global'], 2)   \n",
    "    ax.plot(\n",
    "        time['Global'], a*time['Global']**2 \n",
    "        + b*time['Global'] + c, 'k'\n",
    "    )\n",
    "        \n",
    "    # Global CO2\n",
    "    ax2=ax.twinx()\n",
    "    ax2.plot(timeco2, co2, 'C2', linewidth=3)\n",
    "    # Adjust the y-axis of the figure to show the information more clearly. \n",
    "    ax2.set_ylim(ylim2[count])\n",
    "    ax2.spines['right'].set_color('C2')\n",
    "    ax2.tick_params(axis='y', colors='C2')\n",
    "    ax2.yaxis.label.set_color('C2')\n",
    "\n",
    "\n",
    "    plt.xlim(time['Global'][0], time['Global'][-1])\n",
    "ax2.set_ylabel('Global CO2')\n",
    "axs[0].set_ylabel('Temperature anomaly [¬∞C]')\n",
    "axs[1].set_title('Global')\n",
    "plt.subplots_adjust(wspace=.8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The impression of the relationship between CO2 and temperature is completely dependent on which axis limits we use. A way to check is the changes in each variable is comparable is to look at the normalized time series. This gives a more robust impression of whether the changes are robust relative to internal variability and the mean value or not. \n",
    "\n",
    "The figure below show that both the temperature changes and the CO2 changes are on the same scale. This gives us more confidence that it's ok to use double y-axes with adjusted limits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized trend lines and CO2 üé®\n",
    "\n",
    "# Temp\n",
    "a,b,c = np.polyfit(time['Global'], temp['Global'], 2)   \n",
    "var=a*time['Global']**2 + b*time['Global'] + c\n",
    "# Normaliser: (var-mean)/std\n",
    "var=(var-np.mean(var))/np.std(var)\n",
    "plt.plot(time['Global'], var, 'C0', label='Global')\n",
    "\n",
    "a,b,c = np.polyfit(time['Bergen'], temp['Bergen'], 2)   \n",
    "var=a*time['Bergen']**2 + b*time['Bergen'] + c\n",
    "var=(var-np.mean(var))/np.std(var)\n",
    "plt.plot(time['Bergen'], var, 'C1', label='Bergen')\n",
    "\n",
    "# CO2\n",
    "var=(co2-np.mean(co2))/np.std(co2)\n",
    "plt.plot(timeco2, var, 'k', linewidth=3, label='CO2')\n",
    "\n",
    "plt.xlim(time['Global'][0], time['Global'][-1])\n",
    "plt.ylabel('Temperature anomaly [¬∞C]')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: another feature to be specifically careful with is the use of colormaps: do not use rainbow/hsv/jet, i.e., \"Miscellaneous\" colormaps. These colormaps have uneven transitions between the colors which creates an impression of large changes in data values where this is not necessarily true. \n",
    "\n",
    "#### Now that we're convinced that the relationship between temperature and CO2 is robust, we make the same figure for Bergen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üé®\n",
    "fig, ax=plt.subplots(1, 1, figsize=(10, 4))\n",
    "ax.bar(\n",
    "    time['Bergen'], temp['Bergen'], \n",
    "    color=cmap((temp['Bergen']+max_anomaly)/(2*max_anomaly)) #normalize data values to the range [0, 1]\n",
    ") \n",
    "plt.title('Bergen')\n",
    "ax.set_ylim(-1.5, 2.4)\n",
    "\n",
    "# Polynomial from earlier\n",
    "a,b,c = np.polyfit(time['Bergen'], temp['Bergen'], 2)   \n",
    "ax.plot(\n",
    "    time['Bergen'], a*time['Bergen']**2 \n",
    "    + b*time['Bergen'] + c, 'k'\n",
    ")\n",
    "plt.ylabel('Temperature anomaly [¬∞C]')\n",
    "    \n",
    "# Add global CO2\n",
    "ax2=ax.twinx()\n",
    "ax2.plot(timeco2, co2, 'C2', linewidth=3)\n",
    "ax2.set_ylim(200, 530)\n",
    "ax2.spines['right'].set_color('C2')\n",
    "ax2.tick_params(axis='y', colors='C2')\n",
    "ax2.yaxis.label.set_color('C2')\n",
    "ax2.set_ylabel('Bergen CO2')\n",
    "\n",
    "plt.xlim(time['Bergen'][0], time['Bergen'][-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions**\n",
    "- What do you think the global temperature anomaly will be in 2040? Which assumptions do you make to arrive at your result? \n",
    "- What do you think the temperature anomaly in Bergen will be in 2040?\n",
    "- Which answer do you trust the most? Your anwer regarding Bergen or globally?\n",
    "___________________\n",
    "\n",
    "#### A second note about honest visualization\n",
    "Another aspect to be especially aware of is the use of colormaps: Do not use \"rainbow\", \"hsv\", \"jet\", and other similar color maps! Such color maps are called \"Miscellaneous\" and have uneven rtansitions between colors that create an impression of large changes where this is not necessarily the case.\n",
    "\n",
    "See the example below. The first figure shows the global temperature time series using the same colormat as the figures above. The second figure uses \"hsv\". It's now a lot more difficult to see where abrupt changes actually happen and when the colormap just \"invents\" abrupt changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 2))\n",
    "var=np.tile(temp['Global'], (2, 1))\n",
    "plt.contourf(time['Global'], [0,1], var, 26, vmin=-1.5, vmax=1.5, cmap=cmap)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 2))\n",
    "var=np.tile(temp['Global'], (2, 1))\n",
    "plt.contourf(time['Global'], [0,1], var, 26, vmin=-1.5, vmax=1.5, cmap='hsv')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
